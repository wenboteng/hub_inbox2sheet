services:
  - type: web
    name: ota-answer-hub
    env: node
    buildCommand: |
      npm install
      npx prisma generate
      npm run build
    startCommand: npm start
    envVars:
      - key: DATABASE_URL
        sync: false
      - key: NEXT_PUBLIC_BASE_URL
        sync: false
      - key: OPENAI_API_KEY
        sync: false
      - key: EXPEDIA_USERNAME
        sync: false
      - key: EXPEDIA_PASSWORD
        sync: false
      - key: EXPEDIA_SESSION_COOKIE
        sync: false
      - key: BOOKING_API_TOKEN
        sync: false
      - key: BOOKING_SESSION_COOKIE
        sync: false
      - key: BOOKING_XSRF_TOKEN
        sync: false
      - key: NODE_VERSION
        value: 18.20.2
    buildFilter:
      paths:
        - package.json
        - src/**
        - prisma/**
        - next.config.js
    healthCheckPath: /
    autoDeploy: true 

# Scheduled job to run the crawler daily at 2am UTC
jobs:
  - type: cron
    name: ota-answer-hub-crawler
    env: node
    schedule: "0 2 * * *"  # Run daily at 2am UTC
    buildCommand: |
      # Install Node.js dependencies
      npm install
      
      # Generate Prisma client and build
      npx prisma generate
      npm run build
      
      # Install Chrome for Puppeteer with proper error handling
      echo "Installing Chrome for Puppeteer..."
      npx puppeteer browsers install chrome || {
        echo "Failed to install Chrome via puppeteer browsers install, trying alternative method..."
        # Alternative: Install system Chrome if available
        apt-get update && apt-get install -y google-chrome-stable || echo "System Chrome installation failed, will use bundled Chrome"
      }
      
      # Verify Chrome installation
      echo "Verifying Chrome installation..."
      ls -la /opt/render/.cache/puppeteer/chrome/ || echo "Puppeteer cache directory not found"
      
      # Test Puppeteer setup
      echo "Testing Puppeteer setup..."
      npm run test:puppeteer-setup || echo "Puppeteer test failed, but continuing with crawl"
    startCommand: npm run scrape
    envVars:
      - key: DATABASE_URL
        sync: false
      - key: NEXT_PUBLIC_BASE_URL
        sync: false
      - key: OPENAI_API_KEY
        sync: false
      - key: NODE_VERSION
        value: 18.20.2
      - key: PUPPETEER_CACHE_DIR
        value: /opt/render/.cache/puppeteer
      - key: PUPPETEER_SKIP_CHROMIUM_DOWNLOAD
        value: false

  # Scheduled job to run the Airbnb Community crawler daily at 4am UTC
  - type: cron
    name: ota-answer-hub-airbnb-community-crawler
    env: node
    schedule: "0 4 * * *"  # Run daily at 4am UTC
    buildCommand: |
      # Install Node.js dependencies
      npm install
      
      # Generate Prisma client and build
      npx prisma generate
      npm run build
      
      # Install Chrome for Puppeteer with proper error handling
      echo "Installing Chrome for Puppeteer..."
      npx puppeteer browsers install chrome || {
        echo "Failed to install Chrome via puppeteer browsers install, trying alternative method..."
        # Alternative: Install system Chrome if available
        apt-get update && apt-get install -y google-chrome-stable || echo "System Chrome installation failed, will use bundled Chrome"
      }
      
      # Verify Chrome installation
      echo "Verifying Chrome installation..."
      ls -la /opt/render/.cache/puppeteer/chrome/ || echo "Puppeteer cache directory not found"
      
      # Test Puppeteer setup
      echo "Testing Puppeteer setup..."
      npm run test:puppeteer-setup || echo "Puppeteer test failed, but continuing with crawl"
    startCommand: npm run crawl:airbnb-community
    envVars:
      - key: DATABASE_URL
        sync: false
      - key: NEXT_PUBLIC_BASE_URL
        sync: false
      - key: OPENAI_API_KEY
        sync: false
      - key: NODE_VERSION
        value: 18.20.2
      - key: PUPPETEER_CACHE_DIR
        value: /opt/render/.cache/puppeteer
      - key: PUPPETEER_SKIP_CHROMIUM_DOWNLOAD
        value: false 