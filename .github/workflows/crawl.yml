name: Scheduled Crawler

on:
  schedule:
    # Runs every day at 2am UTC; for testing, use '*/20 * * * *' for every 20 minutes
    - cron: '0 2 * * *'
  workflow_dispatch:

jobs:
  crawl:
    runs-on: ubuntu-latest
    env:
      DATABASE_URL: ${{ secrets.DATABASE_URL }}
      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      NEXT_PUBLIC_BASE_URL: ${{ secrets.NEXT_PUBLIC_BASE_URL }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install dependencies
        run: npm install

      - name: Install Playwright browsers
        run: npx playwright install

      - name: Generate Prisma client
        run: npx prisma generate

      - name: Create .env file
        run: |
          echo "DATABASE_URL=${{ secrets.DATABASE_URL }}" >> .env
          echo "OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}" >> .env
          echo "NEXT_PUBLIC_BASE_URL=${{ secrets.NEXT_PUBLIC_BASE_URL }}" >> .env

      - name: Show .env file
        run: cat .env

      - name: Print env
        run: printenv

      - name: Run migrations (migrate deploy)
        run: npx prisma migrate deploy
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        continue-on-error: true

      - name: Run migrations (db push)
        run: npx prisma db push
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        continue-on-error: true

      - name: Run crawler
        run: npx ts-node src/scripts/crawl.ts 