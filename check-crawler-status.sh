#!/bin/bash

echo "ðŸ• Crawler Status Check - $(date)"
echo "=================================="

echo ""
echo "ðŸ“Š Active Crawler Processes:"
echo "----------------------------"
ps aux | grep -E "(collect|scrape|crawl|oxylabs)" | grep -v grep | while read line; do
    echo "  âœ… $line"
done

echo ""
echo "ðŸ“‹ Cron Jobs Status:"
echo "-------------------"
crontab -l | grep -E "(scrape|collect|crawl)" | while read line; do
    echo "  â° $line"
done

echo ""
echo "ðŸ“ Recent Log Activity:"
echo "----------------------"
echo "ðŸ” Oxylabs Crawler (last 5 lines):"
tail -5 /var/log/ota-hub-crawler.log 2>/dev/null || echo "  No log file found"

echo ""
echo "ðŸ” Main Crawler (last 5 lines):"
tail -5 /var/log/ota-hub-main-crawler.log 2>/dev/null || echo "  No log file found"

echo ""
echo "ðŸ“ˆ Database Stats:"
echo "-----------------"
cd /root/projects/hub_inbox2sheet
npm run check:content-stats 2>/dev/null || echo "  Could not check database stats"

echo ""
echo "ðŸ’¡ Quick Commands:"
echo "-----------------"
echo "  â€¢ View all logs: tail -f /var/log/ota-hub-*.log"
echo "  â€¢ Check specific log: tail -f /var/log/ota-hub-crawler.log"
echo "  â€¢ View cron jobs: crontab -l"
echo "  â€¢ Kill all crawlers: pkill -f 'collect\|scrape\|crawl'"
echo "  â€¢ Restart crawlers: ./setup-cron.sh" 